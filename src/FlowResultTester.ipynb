{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peek at the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56878 entries, 0 to 56877\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   srcMac     54725 non-null  object\n",
      " 1    dstMac    54725 non-null  object\n",
      " 2    ethType   56878 non-null  object\n",
      " 3    srcIp     56878 non-null  object\n",
      " 4    dstIp     56878 non-null  object\n",
      " 5    ipProto   56878 non-null  object\n",
      " 6    srcPort   56878 non-null  object\n",
      " 7    dstPort   56878 non-null  object\n",
      " 8    protocol  56878 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading csv file\n",
    "\n",
    "filename = \"AwairAirQuality_70886b100fc6_flowResult.csv\" \n",
    "  \n",
    "# filename = \"LiFXBulb_d073d5018308_flowResult.csv\"\n",
    "\n",
    "# filename = \"PixStarPhotoFrame_e076d033bb85_flowResult.csv\"\n",
    "\n",
    "# filename = \"RingDoorBell_884aea31669d_flowResult.csv\"  \n",
    "\n",
    "# filename = \"TPLinkCamera_f4f26D9351f1_flowResult.csv\"  \n",
    "\n",
    "# filename = \"TribySpeaker_18B79E022044_flowResult.csv\"\n",
    "\n",
    "# filename = \"AmazonEcho/01DUP_CONCATANATED_AmazonEcho_44650d56ccd3_flowResult.csv\"  \n",
    "# filename = \"AmazonEcho/DUP_CONCATANATED_AmazonEcho_44650d56ccd3_flowResult.csv\"  \n",
    " \n",
    "# filename = \"NestProtect/01DUP_CONCATANATED_NestProtect_18b43025bee4_flowResult.csv\"    \n",
    "# filename = \"NestProtect/DUP_CONCATANATED_NestProtect_18b43025bee4_flowResult.csv\"     \n",
    "\n",
    "# filename = \"WithingsSleepSensor/01DUP_CONCATANATED_WithingsSleepSensor_0024e42028c6_flowResult.csv\"     \n",
    "# filename = \"WithingsSleepSensor/DUP_CONCATANATED_WithingsSleepSensor_0024e42028c6_flowResult.csv\"  \n",
    "\n",
    "\n",
    "path = \"\"\n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "# path = \"without_matching_fpd/TCP443_TLS/\"    \n",
    "\n",
    "df = pd.read_csv(\"../data/\" + path + filename)\n",
    "print(df.info())\n",
    "# print(df.iloc[16880])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 56878\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of entries:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srcMac', ' dstMac', ' ethType', ' srcIp', ' dstIp', ' ipProto',\n",
      "       ' srcPort', ' dstPort', ' protocol'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "print(cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the occurences of the protocols in flowResults.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping the entries by protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " protocol\n",
      "arp       51343\n",
      "cdp           1\n",
      "dhcp          1\n",
      "dns        1118\n",
      "icmp          2\n",
      "lpd          96\n",
      "none       3394\n",
      "ntp         190\n",
      "srvloc        1\n",
      "tls         732\n",
      "Name:  protocol, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby([' protocol'])[' protocol'].count())  # .count()  .groupby(' protocol')  [' protocol']  ' srcIp', ' dstIp', ' srcPort', ' dstPort', \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of occurences of each protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " protocol\n",
      "arp       51343\n",
      "cdp           1\n",
      "dhcp          1\n",
      "dns        1118\n",
      "icmp          2\n",
      "lpd          96\n",
      "none       3394\n",
      "ntp         190\n",
      "srvloc        1\n",
      "tls         732\n",
      "Name:  protocol, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(' protocol')[' protocol'].count())  # .count()  .groupby(' protocol')  [' protocol']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing whether the results of the Tester program are the expected ones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing whether there are more than 1 entry for the same IP and Eth flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flows with unique 5-tuples 2153\n"
     ]
    }
   ],
   "source": [
    "# df_1 = df.loc[df[' protocol'].str.contains('tls')]  #  df[' srcPort'].str.contains('56700') & df[' ipProto'].str.contains('17') &   & df[' dstPort'].str.contains('56700') \n",
    "\n",
    "df_1 = df.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort'])[' protocol'].count()\n",
    "\n",
    "print(\"Number of flows with unique 5-tuples\", len(df_1))\n",
    "# print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of total flows df: 56878\n",
      "length of ip flows df: 2153\n",
      "length of eth flows df: 54725\n",
      "ip + eth flows adds up to total\n"
     ]
    }
   ],
   "source": [
    "# df_1 = df.loc[df[' protocol'].str.contains('tls')]  #  df[' srcPort'].str.contains('56700') & df[' ipProto'].str.contains('17') &   & df[' dstPort'].str.contains('56700') \n",
    "\n",
    "# getting the ip and eth flows from the dataframe\n",
    "df_ip = df.loc[~(df[' srcIp'].str.contains('\\*') & df[' dstIp'].str.contains(\"\\*\"))]  # if atleast one ip is not a star\n",
    "df_eth = df.loc[df[' srcIp'].str.contains('\\*') & df[' dstIp'].str.contains(\"\\*\")]  # \n",
    "\n",
    "print(\"length of total flows df:\", len(df))\n",
    "print(\"length of ip flows df:\", len(df_ip))\n",
    "print(\"length of eth flows df:\", len(df_eth))\n",
    "\n",
    "if(len(df) == (len(df_ip)+len(df_eth))):\n",
    "    print(\"ip + eth flows adds up to total\")\n",
    "else:\n",
    "    print(\"ip + eth flows DOES NOT add up to total\")\n",
    "\n",
    "\n",
    "# ss = df.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort'])[' protocol'].count() == 1\n",
    "# df_2 = df.loc[ss.values]\n",
    "# print(\"Number of repeated 5-tuples:\", len(df_2))\n",
    "\n",
    "\n",
    "# ssss = df.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort'])[' protocol'].count() == 1\n",
    "# sss = df[' protocol'].str.contains('tls')\n",
    "# print(type(ssss))\n",
    "# print(ssss.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for the uniqueness of IP flows and Eth flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ip flows: 2152\n",
      "Number of unique eth flows: 7\n",
      "\n",
      "There are repeating entries for ip flows: 5-TUPLES ARE NOT UNIQUE IN THE DATASET\n",
      "There are repeating entries for eth flows: 3-TUPLES ARE NOT UNIQUE IN THE DATASET\n",
      "\n",
      "Number of IP flows that are not unique: 1\n"
     ]
    }
   ],
   "source": [
    "df_ip_unique = df_ip.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort']).count()  # [' protocol']\n",
    "df_eth_unique = df_eth.groupby(['srcMac', ' dstMac', ' ethType']).count()  # [' protocol']\n",
    "\n",
    "print(\"Number of unique ip flows:\", len(df_ip_unique))\n",
    "print(\"Number of unique eth flows:\", len(df_eth_unique))\n",
    "print(\"\")\n",
    "\n",
    "# for ip flows\n",
    "if(len(df_ip) == len(df_ip_unique)):\n",
    "    print(\"All ip flows are unique: 5-TUPLES ARE UNIQUE IN THE DATASET\")\n",
    "else:\n",
    "    print(\"There are repeating entries for ip flows: 5-TUPLES ARE NOT UNIQUE IN THE DATASET\")\n",
    "\n",
    "# for eth flows\n",
    "if(len(df_eth) == len(df_eth_unique)):\n",
    "    print(\"All eth flows are unique: 3-TUPLES ARE UNIQUE IN THE DATASET\")\n",
    "else:\n",
    "    print(\"There are repeating entries for eth flows: 3-TUPLES ARE NOT UNIQUE IN THE DATASET\")\n",
    "\n",
    "# to print the number of IP fllows that are not unique\n",
    "print(\"\\nNumber of IP flows that are not unique:\", len(df_ip_unique.loc[df_ip_unique[' protocol'] > 1]))  \n",
    "\n",
    "# to write the number of repeating ip flows. Considered to be repeating if 2 or more flows have the same 5-tuple\n",
    "df_nonUnique_ipFlows = df_ip_unique.loc[df_ip_unique[' protocol'] > 1]  \n",
    "df_nonUnique_ipFlows.to_csv('../results/repeating_ipFlows/' + filename, na_rep='null')  # writing the repeating entries to a csv file\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing the repeating ipflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           srcMac   dstMac  \\\n",
      " srcIp          dstIp           ipProto  srcPort  dstPort                    \n",
      "0.0.0.0        0.0.0.0         0        *        *              0        0   \n",
      "               255.255.255.255 17       68       67             0        0   \n",
      "103.226.213.30 192.168.1.152   17       123      123            0        0   \n",
      "103.38.121.36  192.168.1.152   17       123      123            0        0   \n",
      "103.76.40.142  192.168.1.152   17       123      123            0        0   \n",
      "\n",
      "                                                            ethType   protocol  \n",
      " srcIp          dstIp           ipProto  srcPort  dstPort                       \n",
      "0.0.0.0        0.0.0.0         0        *        *                1          1  \n",
      "               255.255.255.255 17       68       67               1          1  \n",
      "103.226.213.30 192.168.1.152   17       123      123              1          1  \n",
      "103.38.121.36  192.168.1.152   17       123      123              1          1  \n",
      "103.76.40.142  192.168.1.152   17       123      123              1          1  \n"
     ]
    }
   ],
   "source": [
    "# df.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort'])[' protocol'].count()\n",
    "\n",
    "print(df_ip.groupby([' srcIp', ' dstIp', ' ipProto', ' srcPort', ' dstPort']).count().head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering --> Sample code to be used in notebook for each MUD flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering a MUD flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "df_1 = df.loc[df[' ipProto'].str.contains('6') & (df[' dstPort']=='8883')]  #  df[' srcPort'].str.contains('56700') & df[' ipProto'].str.contains('17') &   & df[' dstPort'].str.contains('56700')    df[' srcPort'].str.contains('8883')\n",
    "print(len(df_1))\n",
    "# print(df_1)\n",
    "df_2 = df.loc[df[' ipProto'].str.contains('6') & (df[' srcPort']=='8883')]  #  df[' srcPort'].str.contains('56700') & df[' ipProto'].str.contains('17') &   & df[' dstPort'].str.contains('56700')    df[' srcPort'].str.contains('8883')\n",
    "print(len(df_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping the classified MUD flow by protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " protocol\n",
      "lpd     34\n",
      "none     1\n",
      "tls     38\n",
      "Name:  protocol, dtype: int64\n",
      " protocol\n",
      "lpd    44\n",
      "tls    65\n",
      "Name:  protocol, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_1.groupby(' protocol')[' protocol'].count())\n",
    "print(df_2.groupby(' protocol')[' protocol'].count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
