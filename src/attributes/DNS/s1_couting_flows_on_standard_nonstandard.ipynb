{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_dir_paths = [\n",
    "    'AwairAirQuality',\n",
    "    'LiFXBulb',\n",
    "    'PixStarPhotoFrame',\n",
    "    'RingDoorBell',\n",
    "    'TPLinkCamera',\n",
    "    'TribySpeaker',\n",
    "    # 'AmazonEcho/1',\n",
    "    # 'AmazonEcho/2',\n",
    "    # 'AmazonEcho/3',\n",
    "    # 'AmazonEcho/4',\n",
    "    # 'AmazonEcho/5',\n",
    "    # 'AmazonEcho/6',\n",
    "    # 'AmazonEcho/7',\n",
    "    # 'AmazonEcho/8',\n",
    "    # 'AmazonEcho/9',\n",
    "    'AmazonEcho',\n",
    "    # 'NestProtect/1',\n",
    "    # 'NestProtect/2',\n",
    "    # 'NestProtect/3',\n",
    "    # 'NestProtect/4',\n",
    "    # 'NestProtect/5',\n",
    "    # 'NestProtect/6',\n",
    "    # 'NestProtect/7',\n",
    "    # 'WithingsSleepSensor/1',\n",
    "    # 'WithingsSleepSensor/2',\n",
    "    # 'WithingsSleepSensor/3',\n",
    "    # 'WithingsSleepSensor/4',\n",
    "    'WithingsSleepSensor',\n",
    "    'SamsungCamera',\n",
    "    'WithingsBabyMonitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run separately for request and response attributes\n",
    "\n",
    "# for RESPONSE attribute files\n",
    "# root_dir_path = '../../../data/attributes/V3/response_attributes'\n",
    "# final_output_file = '../../../results/attributes/DNS/standard_nonstandard_response_attributes.csv'  \n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# for REQUEST attribute files\n",
    "root_dir_path = '../../../data/attributes/V3/request_attributes'\n",
    "final_output_file = '../../../results/attributes/DNS/standard_nonstandard_request_attributes.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_30961/2628211299.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: df of attributes.csv\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Create an empty list to store the data from CSV files\n",
    "data_device = {}\n",
    "\n",
    "for device_dir_path in device_dir_paths:\n",
    "    data_proto = {}\n",
    "    directory_path  = os.path.join(root_dir_path, device_dir_path)\n",
    "    # Get a list of all files in the directory\n",
    "    file_list = os.listdir(directory_path)\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in file_list:\n",
    "        # reading only the attributes files\n",
    "        if 'dnsattributes' in file_name:\n",
    "            proto = file_name.split('attributes')[0]  # tls\n",
    "            # Check if the file is a CSV file\n",
    "            if file_name.endswith('.csv'):\n",
    "                # Create the file path\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                # print(f'device_dir_path: {device_dir_path}  |  proto: {proto}')\n",
    "                # Read the CSV file and append its data to the list\n",
    "                try:\n",
    "                    # df = pd.read_csv(file_path, sep=',,,')\n",
    "                    df = pd.read_csv(file_path, sep=',,,')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    df = pd.DataFrame()  # Create an empty DataFrame \n",
    "\n",
    "                # data.append(df)\n",
    "\n",
    "                data_proto[proto] = df\n",
    "                # data_proto[proto] = 'df'\n",
    "    \n",
    "    data_device[device_dir_path] = data_proto\n",
    "\n",
    "# # Write dictionary as JSON\n",
    "# with open('output.json', 'w') as json_file:\n",
    "#     json.dump(data_device, json_file)\n",
    "\n",
    "# data_device['AwairAirQuality']['tls'][' violations']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the tuples fields + attributes\n",
    "# for i in data_device['AmazonEcho']['dhcp'].columns:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: AwairAirQuality\n",
      "\tAwairAirQuality --> proto: dns\n",
      "\t\tAwairAirQuality:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tAwairAirQuality:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tAwairAirQuality:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  1118\n",
      "device: LiFXBulb\n",
      "\tLiFXBulb --> proto: dns\n",
      "\t\tLiFXBulb:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tLiFXBulb:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tLiFXBulb:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  6292\n",
      "device: PixStarPhotoFrame\n",
      "\tPixStarPhotoFrame --> proto: dns\n",
      "\t\tPixStarPhotoFrame:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tPixStarPhotoFrame:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tPixStarPhotoFrame:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  4842\n",
      "device: RingDoorBell\n",
      "\tRingDoorBell --> proto: dns\n",
      "\t\tRingDoorBell:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tRingDoorBell:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tRingDoorBell:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  486\n",
      "device: TPLinkCamera\n",
      "\tTPLinkCamera --> proto: dns\n",
      "\t\tTPLinkCamera:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tTPLinkCamera:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tTPLinkCamera:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  4826\n",
      "\tTPLinkCamera --> proto: mdns\n",
      "\t\tTPLinkCamera:mdns --> attr: additional records count   |   non-standard instances: 4\n",
      "\t\tTPLinkCamera:mdns --> attr: answer records count   |   non-standard instances: 4\n",
      "\t\tTPLinkCamera:mdns --> attr: flags   |   non-standard instances: 4\n",
      "\t\tTPLinkCamera:mdns --> attr: authority records count   |   non-standard instances: 4\n",
      "\t\tTPLinkCamera:mdns --> attr: questions count,,   |   non-standard instances: 4\n",
      "\t\t\tnumber of unique flows:  4\n",
      "device: TribySpeaker\n",
      "\tTribySpeaker --> proto: dns\n",
      "\t\tTribySpeaker:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tTribySpeaker:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tTribySpeaker:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  3914\n",
      "\tTribySpeaker --> proto: mdns\n",
      "\t\tTribySpeaker:mdns --> attr: additional records count   |   non-standard instances: 3\n",
      "\t\tTribySpeaker:mdns --> attr: answer records count   |   non-standard instances: 3\n",
      "\t\tTribySpeaker:mdns --> attr: flags   |   non-standard instances: 3\n",
      "\t\tTribySpeaker:mdns --> attr: authority records count   |   non-standard instances: 3\n",
      "\t\tTribySpeaker:mdns --> attr: questions count,,   |   non-standard instances: 3\n",
      "\t\t\tnumber of unique flows:  3\n",
      "device: AmazonEcho\n",
      "\tAmazonEcho --> proto: dns\n",
      "\t\tAmazonEcho:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tAmazonEcho:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tAmazonEcho:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  56189\n",
      "device: WithingsSleepSensor\n",
      "\tWithingsSleepSensor --> proto: dns\n",
      "\t\tWithingsSleepSensor:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tWithingsSleepSensor:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tWithingsSleepSensor:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  14647\n",
      "device: SamsungCamera\n",
      "\tSamsungCamera --> proto: dns\n",
      "\t\tSamsungCamera:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tSamsungCamera:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tSamsungCamera:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  20146\n",
      "device: WithingsBabyMonitor\n",
      "\tWithingsBabyMonitor --> proto: dns\n",
      "\t\tWithingsBabyMonitor:dns --> attr: transaction id   |   non-standard instances: 0\n",
      "\t\tWithingsBabyMonitor:dns --> attr: flags   |   non-standard instances: 0\n",
      "\t\tWithingsBabyMonitor:dns --> attr: Qnumber,,   |   non-standard instances: 0\n",
      "\t\t\tnumber of unique flows:  5068\n",
      "\tWithingsBabyMonitor --> proto: mdns\n",
      "\t\t\tnumber of unique flows:  5068\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "unique_attr_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: {\n",
    "                attr_name: {\n",
    "                    standard:{}\n",
    "                        value_attr: number_of_ccurences,\n",
    "                        ...\n",
    "                    },\n",
    "                    non_standard:{}\n",
    "                        value_attr: number_of_ccurences,\n",
    "                        ...\n",
    "                    }\n",
    "                }\n",
    "                ...\n",
    "                'unique_flows_using_attribute': [list of unique flows]\n",
    "                'num_violated_flows': len(unique_flows_using_attribute)\n",
    "            },\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# srcMac, dstMac, ethType, srcIp, dstIp, ipProto, srcPort, dstPort\n",
    "\n",
    "unique_attr_device = {}\n",
    "for device, protos in data_device.items():  # per device\n",
    "    print('device:', device)\n",
    "    unique_attr_proto = {}\n",
    "    for proto, df in protos.items():  # per protocol\n",
    "\n",
    "        if True:  # proto == 'tls':  # running only for a selected protocol ######################################################################\n",
    "            print(f'\\t{device} --> proto: {proto}')\n",
    "            attr = {}\n",
    "            # num_violated_flows = 0\n",
    "            # print(\"df columns:\", df.columns)\n",
    "            for col in df.columns[8:]:\n",
    "                \n",
    "                if col == 'server-hello-certificates':  # skipping a specific attribute ######################################################################\n",
    "                    continue\n",
    "                if (device == 'AwairAirQuality' or device == 'LiFXBulb') and col == 'client-hello-extensions':\n",
    "                    continue\n",
    "\n",
    "                print(f'\\t\\t{device}:{proto} --> attr: {col}', end='')\n",
    "                unique_flows_using_attribute = []   \n",
    "                # attr_name = col\n",
    "                attr_name_dict_standardPort = {}\n",
    "                attr_name_dict_NONstandardPort = {}\n",
    "                non_standard_MUDFlows = {}\n",
    "                total_non_standard = 0  # used to check whether the attribute has any values on non-standard ports\n",
    "                for index in df.index:  # per line in the df\n",
    "                    # print('\\t\\t\\tindex:', index)\n",
    "                    value_attr = df[col][index]  ####\n",
    "                    # if value_attr == ' ':\n",
    "                    # print(f'{device}:{proto}:{col} --> {value_attr}')\n",
    "                    # making a flow signature\n",
    "                    value_flow = df[' srcIp'][index] + '-' + df[' dstIp'][index] + '-' + str(df[' ipProto'][index]) + '-' + str(df[' srcPort'][index]) + '-' + str(df[' dstPort'][index])\n",
    "                    \n",
    "                    if df[' ipProto'][index] == 17 and (df[' srcPort'][index]==53 or df[' dstPort'][index]==53):  ## change the value of the standard port\n",
    "                        if value_attr not in attr_name_dict_standardPort:\n",
    "                            attr_name_dict_standardPort[value_attr] = 0\n",
    "                        attr_name_dict_standardPort[value_attr] += 1\n",
    "                    else:  # non-standard port\n",
    "                        if value_attr not in attr_name_dict_NONstandardPort:\n",
    "                            attr_name_dict_NONstandardPort[value_attr] = 0\n",
    "                        attr_name_dict_NONstandardPort[value_attr] += 1\n",
    "                        total_non_standard += 1\n",
    "\n",
    "                        # recording the non-standard flow used\n",
    "                        flowSig = str(df[' ipProto'][index]) + '-' + str(df[' srcPort'][index]) + '-' + str(df[' dstPort'][index])\n",
    "                        if flowSig not in non_standard_MUDFlows:\n",
    "                            non_standard_MUDFlows[flowSig] = 0\n",
    "                        non_standard_MUDFlows[flowSig] += 1                \n",
    "\n",
    "                    if value_flow not in unique_flows_using_attribute:  # adding unique flow with a violation\n",
    "                        unique_flows_using_attribute.append(value_flow)  \n",
    "                        # num_violated_flows += 1\n",
    "                # attr_name_dict['unique_flows_using_attribute'] = []  # unique_flows_using_attribute  # commented out because not needed at this point, can uncomment to be used later\n",
    "                # attr_name_dict['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "                attr[col] = {'standard': attr_name_dict_standardPort, 'nonstandard': attr_name_dict_NONstandardPort}\n",
    "                print('   |   non-standard instances:', total_non_standard)\n",
    "            attr['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "            # attr['nonstandard_flows'] = non_standard_MUDFlows  # can include the non-standard flows and their number of occurences\n",
    "            unique_attr_proto[proto] = attr\n",
    "            print(f'\\t\\t\\tnumber of unique flows: ', len(unique_flows_using_attribute))\n",
    "\n",
    "    # #####################################################################\n",
    "    # df_to_save_temp = pd.DataFrame(unique_attr_proto)\n",
    "    # # Specify the output CSV file path\n",
    "    # output_file = '../../results/attributes/delete/'+device+'.csv'\n",
    "    # # if os.path.exists(output_dir):\n",
    "    # #     shutil.rmtree(output_dir)\n",
    "    # # os.mkdir(output_dir)\n",
    "    # # Write the DataFrame to the CSV file\n",
    "    # df_to_save_temp.to_csv(df_to_save_temp, index=True, sep='|')\n",
    "    # #####################################################################\n",
    "\n",
    "    unique_attr_device[device] = unique_attr_proto\n",
    "\n",
    "# with open('output2.json', 'w') as json_file:\n",
    "#     json.dump(unique_viol_device, json_file)\n",
    "# print(unique_attr_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_save = pd.DataFrame(unique_attr_device)\n",
    "# df_to_save['TPLinkCamera']['classic-stun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwairAirQuality</th>\n",
       "      <th>LiFXBulb</th>\n",
       "      <th>PixStarPhotoFrame</th>\n",
       "      <th>RingDoorBell</th>\n",
       "      <th>TPLinkCamera</th>\n",
       "      <th>TribySpeaker</th>\n",
       "      <th>AmazonEcho</th>\n",
       "      <th>WithingsSleepSensor</th>\n",
       "      <th>SamsungCamera</th>\n",
       "      <th>WithingsBabyMonitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dns</th>\n",
       "      <td>{'transaction id': {'standard': {0: 1118}, 'no...</td>\n",
       "      <td>{'transaction id': {'standard': {0: 6292}, 'no...</td>\n",
       "      <td>{'transaction id': {'standard': {'7314': 1, '7...</td>\n",
       "      <td>{'transaction id': {'standard': {'23a2': 1, 'f...</td>\n",
       "      <td>{'transaction id': {'standard': {'0d0d': 1, '0...</td>\n",
       "      <td>{'transaction id': {'standard': {'64bd': 1, '0...</td>\n",
       "      <td>{'transaction id': {'standard': {'234c': 5, '7...</td>\n",
       "      <td>{'transaction id': {'standard': {'7fcf': 1, 'a...</td>\n",
       "      <td>{'transaction id': {'standard': {'fea8': 1, 'c...</td>\n",
       "      <td>{'transaction id': {'standard': {'d1af': 1, 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdns</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'additional records count': {'standard': {}, ...</td>\n",
       "      <td>{'additional records count': {'standard': {}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'number_of_unique_flows': 5068}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        AwairAirQuality  \\\n",
       "dns   {'transaction id': {'standard': {0: 1118}, 'no...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                               LiFXBulb  \\\n",
       "dns   {'transaction id': {'standard': {0: 6292}, 'no...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                      PixStarPhotoFrame  \\\n",
       "dns   {'transaction id': {'standard': {'7314': 1, '7...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                           RingDoorBell  \\\n",
       "dns   {'transaction id': {'standard': {'23a2': 1, 'f...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                           TPLinkCamera  \\\n",
       "dns   {'transaction id': {'standard': {'0d0d': 1, '0...   \n",
       "mdns  {'additional records count': {'standard': {}, ...   \n",
       "\n",
       "                                           TribySpeaker  \\\n",
       "dns   {'transaction id': {'standard': {'64bd': 1, '0...   \n",
       "mdns  {'additional records count': {'standard': {}, ...   \n",
       "\n",
       "                                             AmazonEcho  \\\n",
       "dns   {'transaction id': {'standard': {'234c': 5, '7...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                    WithingsSleepSensor  \\\n",
       "dns   {'transaction id': {'standard': {'7fcf': 1, 'a...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                          SamsungCamera  \\\n",
       "dns   {'transaction id': {'standard': {'fea8': 1, 'c...   \n",
       "mdns                                                NaN   \n",
       "\n",
       "                                    WithingsBabyMonitor  \n",
       "dns   {'transaction id': {'standard': {'d1af': 1, 'a...  \n",
       "mdns                   {'number_of_unique_flows': 5068}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_save = pd.DataFrame(unique_attr_device)\n",
    "\n",
    "# Specify the output CSV file path\n",
    "# final_output_file = '../../results/attributes/v1_request_attributes.csv'  # define in the beginning\n",
    "\n",
    "# Write the DataFrame to the CSV file\n",
    "df_to_save.to_csv(final_output_file, index=True, sep='|')\n",
    "\n",
    "df_to_save.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
