{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_dir_paths = [\n",
    "    'AwairAirQuality',\n",
    "    'LiFXBulb',\n",
    "    'PixStarPhotoFrame',\n",
    "    'RingDoorBell',\n",
    "    'TPLinkCamera',\n",
    "    'TribySpeaker',\n",
    "\n",
    "    # 'AmazonEcho/1',\n",
    "    # 'AmazonEcho/2',\n",
    "    # 'AmazonEcho/3',\n",
    "    # 'AmazonEcho/4',\n",
    "    # 'AmazonEcho/5',\n",
    "    # 'AmazonEcho/6',\n",
    "    # 'AmazonEcho/7',\n",
    "    # 'AmazonEcho/8',\n",
    "    # 'AmazonEcho/9',\n",
    "    'AmazonEcho',\n",
    "\n",
    "    # 'NestProtect/1',\n",
    "    # 'NestProtect/2',\n",
    "    # 'NestProtect/3',\n",
    "    # 'NestProtect/4',\n",
    "    # 'NestProtect/5',\n",
    "    # 'NestProtect/6',\n",
    "    # 'NestProtect/7',\n",
    "\n",
    "    # 'WithingsSleepSensor/1',\n",
    "    # 'WithingsSleepSensor/2',\n",
    "    # 'WithingsSleepSensor/3',\n",
    "    # 'WithingsSleepSensor/4',\n",
    "    'WithingsSleepSensor',\n",
    "\n",
    "    # 'SamsungCamera/1',\n",
    "    # 'SamsungCamera/2',\n",
    "    # 'SamsungCamera/3',\n",
    "    # 'SamsungCamera/4',\n",
    "    # 'SamsungCamera/5',\n",
    "    # 'SamsungCamera/6',\n",
    "    # 'SamsungCamera/7',\n",
    "    # 'SamsungCamera/8',\n",
    "    # 'SamsungCamera/9',\n",
    "    # 'SamsungCamera/10',\n",
    "    # 'SamsungCamera/11',\n",
    "    # 'SamsungCamera/12',\n",
    "    'SamsungCamera',\n",
    "\n",
    "    'WithingsBabyMonitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RESPONSE attribute files\n",
    "# root_dir_path = '../../data/attributes/V3/response_attributes'\n",
    "# final_output_file = '../../results/attributes/NTP/ntp_refID_response_attributes.csv'  \n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# for REQUEST attribute files\n",
    "root_dir_path = '../../../data/attributes/V3/request_dns_domain_names'\n",
    "final_output_file = '../../../results/attributes/DNS/dns_domainName_request_attributes.csv'  \n",
    "\n",
    "checkedProto = 'dns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_dir_path: AwairAirQuality\n",
      "filename: dnsattributes.csv\n",
      "device_dir_path: LiFXBulb\n",
      "filename: dnsattributes.csv\n",
      "device_dir_path: PixStarPhotoFrame\n",
      "filename: dnsattributes.csv\n",
      "device_dir_path: RingDoorBell\n",
      "filename: dnsattributes.csv\n",
      "device_dir_path: TPLinkCamera\n",
      "filename: dnsattributes.csv\n",
      "device_dir_path: TribySpeaker\n",
      "filename: dnsattributes.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n",
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n",
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n",
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n",
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n",
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_dir_path: AmazonEcho\n",
      "filename: 5\n",
      "filename: 4\n",
      "filename: 6\n",
      "filename: concatAmazonEchoResAttr.ipynb\n",
      "filename: 9\n",
      "filename: dnsattributes.csv\n",
      "filename: 2\n",
      "filename: 7\n",
      "filename: 1\n",
      "filename: 8\n",
      "filename: 3\n",
      "device_dir_path: WithingsSleepSensor\n",
      "filename: 4\n",
      "filename: dnsattributes.csv\n",
      "filename: 2\n",
      "filename: concatWithingsSleepSensorResAttr.ipynb\n",
      "filename: 1\n",
      "filename: 3\n",
      "device_dir_path: SamsungCamera\n",
      "filename: 5\n",
      "filename: 4\n",
      "filename: 6\n",
      "filename: 10\n",
      "filename: 12\n",
      "filename: 11\n",
      "filename: 9\n",
      "filename: dnsattributes.csv\n",
      "filename: 2\n",
      "filename: 7\n",
      "filename: 1\n",
      "filename: 8\n",
      "filename: 3\n",
      "filename: concatSamsungCameraReqAttr.ipynb\n",
      "device_dir_path: WithingsBabyMonitor\n",
      "filename: dnsattributes.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12920/3426504225.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=sepa)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: df of attributes.csv\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Create an empty list to store the data from CSV files\n",
    "data_device = {}\n",
    "\n",
    "for device_dir_path in device_dir_paths:\n",
    "    # this is needed because for outputs from the java script the separator is ',,,'.\n",
    "    # but for devices with concatanated attribute files the separator is '/'\n",
    "    if device_dir_path == 'SamsungCamera' or device_dir_path == 'AmazonEcho' or device_dir_path == 'WithingsSleepSensor':\n",
    "        sepa = '|'\n",
    "    else:\n",
    "        sepa = ',,,'\n",
    "    data_proto = {}\n",
    "    print(f'device_dir_path: {device_dir_path}')\n",
    "    directory_path  = os.path.join(root_dir_path, device_dir_path)\n",
    "    # print(f'directory_path: {directory_path}')\n",
    "    # Get a list of all files in the directory\n",
    "    file_list = os.listdir(directory_path)\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in file_list:\n",
    "        print(f'filename: {file_name}')\n",
    "        # reading only the attributes files\n",
    "        if 'attributes' in file_name:\n",
    "            proto = file_name.split('attributes')[0]\n",
    "            # Check if the file is a CSV file\n",
    "            if file_name.endswith('.csv'):\n",
    "                # Create the file path\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                # print(f'device_dir_path: {device_dir_path}  |  proto: {proto}')\n",
    "                # Read the CSV file and append its data to the list\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, sep=sepa)\n",
    "                    # df = pd.read_csv(file_path, sep='|')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    df = pd.DataFrame()  # Create an empty DataFrame \n",
    "\n",
    "                # data.append(df)\n",
    "\n",
    "                data_proto[proto] = df\n",
    "                # data_proto[proto] = 'df'\n",
    "    \n",
    "    data_device[device_dir_path] = data_proto\n",
    "\n",
    "# # Write dictionary as JSON\n",
    "# with open('output.json', 'w') as json_file:\n",
    "#     json.dump(data_device, json_file)\n",
    "\n",
    "# data_device['AwairAirQuality']['tls'][' violations']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data_device['LiFXBulb']['dhcp'].columns:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes_to_domain_name(domain_bytes):\n",
    "    domain_parts = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(domain_bytes):\n",
    "        label_length = domain_bytes[i]\n",
    "        if label_length == 0:\n",
    "            break\n",
    "        \n",
    "        label = domain_bytes[i+1:i+1+label_length].decode('utf-8')\n",
    "        domain_parts.append(label)\n",
    "        i += label_length + 1\n",
    "\n",
    "    return '.'.join(domain_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savinduuu\n",
      "\t\t\tnumber of unique flows:  1118\n",
      "\t\t\tnumber of unique flows:  6292\n",
      "\t\t\tnumber of unique flows:  4843\n",
      "\t\t\tnumber of unique flows:  486\n",
      "\t\t\tnumber of unique flows:  4826\n",
      "\t\t\tnumber of unique flows:  3914\n",
      "\t\t\tnumber of unique flows:  56189\n",
      "\t\tWithingsSleepSensor:dns --> attr: domain name,,\n",
      "index: 9337\n",
      "value_attr: nan\n",
      "value_attr: <class 'float'>\n",
      "\t\tWithingsSleepSensor:dns --> attr: domain name,,\n",
      "index: 14063\n",
      "value_attr: nan\n",
      "value_attr: <class 'float'>\n",
      "\t\t\tnumber of unique flows:  14647\n",
      "\t\t\tnumber of unique flows:  20146\n",
      "\t\t\tnumber of unique flows:  5068\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "unique_attr_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: {\n",
    "                attr_name: {\n",
    "                    value_attr: number_of_ccurences,\n",
    "                    ...\n",
    "                }\n",
    "                ...\n",
    "                'unique_flows_using_attribute': [list of unique flows]\n",
    "                'num_violated_flows': len(unique_flows_using_attribute)\n",
    "            },\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# srcMac, dstMac, ethType, srcIp, dstIp, ipProto, srcPort, dstPort\n",
    "print(f'savinduuu')\n",
    "unique_attr_device = {}\n",
    "for device, protos in data_device.items():  # per device\n",
    "    # print('device:', device)\n",
    "    unique_attr_proto = {}\n",
    "    for proto, df in protos.items():  # per protocol\n",
    "\n",
    "        if proto == checkedProto:  # proto == 'tls':  # running only for a selected protocol ######################################################################\n",
    "            # print(f'\\t{device} --> proto: {proto}')\n",
    "            attr = {}\n",
    "            # num_violated_flows = 0\n",
    "            # print(df.columns)\n",
    "            for col in df.columns[8:]:\n",
    "                \n",
    "                # if col == 'server-hello-certificates':  # TLS skipping a specific attribute ######################################################################\n",
    "                #     continue\n",
    "                # if 'uri' in col:  # HTTP skipping a specific attribute ######################################################################\n",
    "                #     continue\n",
    "                # if col == 'origin timestamp' or col == 'transmit timestamp' or col == 'reference id':  # NTP skipping a specific attribute ######################################################################\n",
    "                    # continue\n",
    "                # if col != 'reference id':  # NTP specific attribute ######################################################################\n",
    "                #     continue\n",
    "                # if col == 'transaction id':  # DNS skipping a specific attribute ######################################################################\n",
    "                #     continue\n",
    "\n",
    "                # # checing only the transaction ID \n",
    "                # if col != 'transaction id':  # DNS skipping a specific attribute ######################################################################\n",
    "                #     continue\n",
    "                \n",
    "                # checing only the transaction ID \n",
    "                if 'domain name' not in col:  # DHCP skipping a specific attribute ######################################################################\n",
    "                    continue\n",
    "\n",
    "                # print(f'\\t\\t{device}:{proto} --> attr: {col}')\n",
    "                unique_flows_using_attribute = []   \n",
    "                # attr_name = col\n",
    "                attr_name_dict = {}\n",
    "                for index in df.index:  # per line in the df\n",
    "                    # print('\\t\\t\\tindex:', index)\n",
    "                    value_attr = df[col][index]  ####\n",
    "                    if type(value_attr) != str:\n",
    "                        print(f'\\t\\t{device}:{proto} --> attr: {col}')\n",
    "                        print(f'index: {index}')\n",
    "                        print(f'value_attr: {value_attr}')\n",
    "                        print(f'value_attr: {type(value_attr)}')\n",
    "                        continue\n",
    "\n",
    "                    value_attr = value_attr.split(',,')[0]\n",
    "\n",
    "                    domain_name_bytes = bytes.fromhex(value_attr)\n",
    "                    domain_name_string = convert_bytes_to_domain_name(domain_name_bytes)\n",
    "\n",
    "                    \n",
    "                    value_flow = df[' srcIp'][index] + '-' + df[' dstIp'][index] + '-' + str(df[' ipProto'][index]) + '-' + str(df[' srcPort'][index]) + '-' + str(df[' dstPort'][index])\n",
    "                    \n",
    "                    if domain_name_string not in attr_name_dict:\n",
    "                        attr_name_dict[domain_name_string] = 0\n",
    "                    attr_name_dict[domain_name_string] += 1\n",
    "\n",
    "                    if value_flow not in unique_flows_using_attribute:  # adding unique flow with a violation\n",
    "                        unique_flows_using_attribute.append(value_flow)  \n",
    "                        # num_violated_flows += 1\n",
    "                # attr_name_dict['unique_flows_using_attribute'] = []  # unique_flows_using_attribute  # commented out because not needed at this point, can uncomment to be used later\n",
    "                # attr_name_dict['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "                attr[col] = attr_name_dict\n",
    "\n",
    "            attr['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "            \n",
    "            unique_attr_proto[proto] = attr\n",
    "            print(f'\\t\\t\\tnumber of unique flows: ', len(unique_flows_using_attribute))\n",
    "\n",
    "    # #####################################################################\n",
    "    # df_to_save_temp = pd.DataFrame(unique_attr_proto)\n",
    "    # # Specify the output CSV file path\n",
    "    # output_file = '../../results/attributes/delete/'+device+'.csv'\n",
    "    # # if os.path.exists(output_dir):\n",
    "    # #     shutil.rmtree(output_dir)\n",
    "    # # os.mkdir(output_dir)\n",
    "    # # Write the DataFrame to the CSV file\n",
    "    # df_to_save_temp.to_csv(df_to_save_temp, index=True, sep='|')\n",
    "    # #####################################################################\n",
    "\n",
    "    unique_attr_device[device] = unique_attr_proto\n",
    "\n",
    "# with open('output2.json', 'w') as json_file:\n",
    "#     json.dump(unique_viol_device, json_file)\n",
    "# print(unique_attr_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_save = pd.DataFrame(unique_attr_device)\n",
    "# df_to_save['TPLinkCamera']['classic-stun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwairAirQuality</th>\n",
       "      <th>LiFXBulb</th>\n",
       "      <th>PixStarPhotoFrame</th>\n",
       "      <th>RingDoorBell</th>\n",
       "      <th>TPLinkCamera</th>\n",
       "      <th>TribySpeaker</th>\n",
       "      <th>AmazonEcho</th>\n",
       "      <th>WithingsSleepSensor</th>\n",
       "      <th>SamsungCamera</th>\n",
       "      <th>WithingsBabyMonitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dns</th>\n",
       "      <td>{'domain name,,': {'pool.ntp.org': 400, 'times...</td>\n",
       "      <td>{'domain name,,': {'pool.ntp.org': 6268, 'v2.b...</td>\n",
       "      <td>{'domain name,,': {'api.pix-star.com': 1818, '...</td>\n",
       "      <td>{'domain name,,': {'fw.ring.com': 459, '2.pool...</td>\n",
       "      <td>{'domain name,,': {'aps1-relay.tplinkcl': 3214...</td>\n",
       "      <td>{'domain name,,': {'ws.invoxia.io': 3556, 'sip...</td>\n",
       "      <td>{'domain name,,': {'device-metrics-us.a': 8286...</td>\n",
       "      <td>{'domain name,,': {'scalews.withings.ne': 1847...</td>\n",
       "      <td>{'domain name,,': {'smtp.gmail.com': 8426, 'ww...</td>\n",
       "      <td>{'domain name,,': {'babyws.withings.net': 5055...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       AwairAirQuality  \\\n",
       "dns  {'domain name,,': {'pool.ntp.org': 400, 'times...   \n",
       "\n",
       "                                              LiFXBulb  \\\n",
       "dns  {'domain name,,': {'pool.ntp.org': 6268, 'v2.b...   \n",
       "\n",
       "                                     PixStarPhotoFrame  \\\n",
       "dns  {'domain name,,': {'api.pix-star.com': 1818, '...   \n",
       "\n",
       "                                          RingDoorBell  \\\n",
       "dns  {'domain name,,': {'fw.ring.com': 459, '2.pool...   \n",
       "\n",
       "                                          TPLinkCamera  \\\n",
       "dns  {'domain name,,': {'aps1-relay.tplinkcl': 3214...   \n",
       "\n",
       "                                          TribySpeaker  \\\n",
       "dns  {'domain name,,': {'ws.invoxia.io': 3556, 'sip...   \n",
       "\n",
       "                                            AmazonEcho  \\\n",
       "dns  {'domain name,,': {'device-metrics-us.a': 8286...   \n",
       "\n",
       "                                   WithingsSleepSensor  \\\n",
       "dns  {'domain name,,': {'scalews.withings.ne': 1847...   \n",
       "\n",
       "                                         SamsungCamera  \\\n",
       "dns  {'domain name,,': {'smtp.gmail.com': 8426, 'ww...   \n",
       "\n",
       "                                   WithingsBabyMonitor  \n",
       "dns  {'domain name,,': {'babyws.withings.net': 5055...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_save = pd.DataFrame(unique_attr_device)\n",
    "\n",
    "# Specify the output CSV file path\n",
    "# final_output_file = '../../results/attributes/v1_request_attributes.csv'  # define in the beginning\n",
    "\n",
    "# Write the DataFrame to the CSV file\n",
    "df_to_save.to_csv(final_output_file, index=True, sep='|')\n",
    "\n",
    "df_to_save.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
