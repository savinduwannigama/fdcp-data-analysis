{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas as pd\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_dir_paths = [\n",
    "    'AwairAirQuality',\n",
    "    'LiFXBulb',\n",
    "    # 'PixStarPhotoFrame',\n",
    "    # 'RingDoorBell',\n",
    "    'TPLinkCamera',\n",
    "    # 'TribySpeaker',\n",
    "    # 'AmazonEcho/1',\n",
    "    # 'AmazonEcho/2',\n",
    "    # 'AmazonEcho/3',\n",
    "    # 'AmazonEcho/4',\n",
    "    # 'AmazonEcho/5',\n",
    "    # 'AmazonEcho/6',\n",
    "    # 'AmazonEcho/7',\n",
    "    # 'AmazonEcho/8',\n",
    "    # 'AmazonEcho/9',\n",
    "    # 'NestProtect/1',\n",
    "    # 'NestProtect/2',\n",
    "    # 'NestProtect/3',\n",
    "    # 'NestProtect/4',\n",
    "    # 'NestProtect/5',\n",
    "    # 'NestProtect/6',\n",
    "    # 'NestProtect/7',\n",
    "    # 'WithingsSleepSensor/1',\n",
    "    # 'WithingsSleepSensor/2',\n",
    "    # 'WithingsSleepSensor/3',\n",
    "    # 'WithingsSleepSensor/4',\n",
    "    # 'SamsungCamera',\n",
    "    # 'WithingsBabyMonitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RESPONSE attribute files\n",
    "# root_dir_path = '../../../data/attributes/V3/response_attributes'\n",
    "# final_output_file = '../../../results/attributes/TLS/standard_nonstandard_response_attributes.csv'  \n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# for REQUEST attribute files\n",
    "root_dir_path = '../../../data/attributes/V3/request_attributes'\n",
    "final_output_file = '../../../results/attributes/TLS/standard_nonstandard_request_attributes.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12164/308301489.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_12164/308301489.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n",
      "/tmp/ipykernel_12164/308301489.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=',,,')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: df of attributes.csv\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Create an empty list to store the data from CSV files\n",
    "data_device = {}\n",
    "\n",
    "for device_dir_path in device_dir_paths:\n",
    "    data_proto = {}\n",
    "    directory_path  = os.path.join(root_dir_path, device_dir_path)\n",
    "    # Get a list of all files in the directory\n",
    "    file_list = os.listdir(directory_path)\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in file_list:\n",
    "        # reading only the attributes files\n",
    "        if 'tlsattributes' in file_name:\n",
    "            proto = file_name.split('attributes')[0]  # tls\n",
    "            # Check if the file is a CSV file\n",
    "            if file_name.endswith('.csv'):\n",
    "                # Create the file path\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                # print(f'device_dir_path: {device_dir_path}  |  proto: {proto}')\n",
    "                # Read the CSV file and append its data to the list\n",
    "                try:\n",
    "                    # df = pd.read_csv(file_path, sep=',,,')\n",
    "                    df = pd.read_csv(file_path, sep=',,,')\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    df = pd.DataFrame()  # Create an empty DataFrame \n",
    "\n",
    "                # data.append(df)\n",
    "\n",
    "                data_proto[proto] = df\n",
    "                # data_proto[proto] = 'df'\n",
    "    \n",
    "    data_device[device_dir_path] = data_proto\n",
    "\n",
    "# # Write dictionary as JSON\n",
    "# with open('output.json', 'w') as json_file:\n",
    "#     json.dump(data_device, json_file)\n",
    "\n",
    "# data_device['AwairAirQuality']['tls'][' violations']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcMac\n",
      " dstMac\n",
      " ethType\n",
      " srcIp\n",
      " dstIp\n",
      " ipProto\n",
      " srcPort\n",
      " dstPort\n",
      "client-hello-extensions\n",
      "client-hello-cipher-suites\n",
      "client-hello-version,,\n"
     ]
    }
   ],
   "source": [
    "for i in data_device['LiFXBulb']['tls'].columns:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: AwairAirQuality\n",
      "\tAwairAirQuality --> proto: tls\n",
      "\t\tAwairAirQuality:tls --> attr: client-hello-cipher-suites\n",
      "\t\tAwairAirQuality:tls --> attr: client-hello-version,,\n",
      "\t\t\tnumber of unique flows:  826\n",
      "device: LiFXBulb\n",
      "\tLiFXBulb --> proto: tls\n",
      "\t\tLiFXBulb:tls --> attr: client-hello-cipher-suites\n",
      "\t\tLiFXBulb:tls --> attr: client-hello-version,,\n",
      "\t\t\tnumber of unique flows:  131\n",
      "device: TPLinkCamera\n",
      "\tTPLinkCamera --> proto: tls\n",
      "\t\tTPLinkCamera:tls --> attr: client-hello-extensions\n",
      "\t\tTPLinkCamera:tls --> attr: client-hello-cipher-suites\n",
      "\t\tTPLinkCamera:tls --> attr: client-hello-version,,\n",
      "\t\t\tnumber of unique flows:  26\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "unique_attr_device =    \n",
    "    {\n",
    "        device: {\n",
    "            protocol: {\n",
    "                attr_name: {\n",
    "                    standard:{}\n",
    "                        value_attr: number_of_ccurences,\n",
    "                        ...\n",
    "                    },\n",
    "                    non_standard:{}\n",
    "                        value_attr: number_of_ccurences,\n",
    "                        ...\n",
    "                    }\n",
    "                }\n",
    "                ...\n",
    "                'unique_flows_using_attribute': [list of unique flows]\n",
    "                'num_violated_flows': len(unique_flows_using_attribute)\n",
    "            },\n",
    "            ...\n",
    "        } ,\n",
    "        ...\n",
    "    }\n",
    "'''\n",
    "\n",
    "# srcMac, dstMac, ethType, srcIp, dstIp, ipProto, srcPort, dstPort\n",
    "\n",
    "unique_attr_device = {}\n",
    "for device, protos in data_device.items():  # per device\n",
    "    print('device:', device)\n",
    "    unique_attr_proto = {}\n",
    "    for proto, df in protos.items():  # per protocol\n",
    "\n",
    "        if True:  # proto == 'tls':  # running only for a selected protocol ######################################################################\n",
    "            print(f'\\t{device} --> proto: {proto}')\n",
    "            attr = {}\n",
    "            # num_violated_flows = 0\n",
    "\n",
    "            for col in df.columns[8:]:\n",
    "                \n",
    "                if col == 'server-hello-certificates':  # skipping a specific attribute ######################################################################\n",
    "                    continue\n",
    "                if (device == 'AwairAirQuality' or device == 'LiFXBulb') and col == 'client-hello-extensions':\n",
    "                    continue\n",
    "\n",
    "                print(f'\\t\\t{device}:{proto} --> attr: {col}')\n",
    "                unique_flows_using_attribute = []   \n",
    "                # attr_name = col\n",
    "                attr_name_dict_standardPort = {}\n",
    "                attr_name_dict_NONstandardPort = {}\n",
    "                non_standard_MUDFlows = {}\n",
    "                for index in df.index:  # per line in the df\n",
    "                    # print('\\t\\t\\tindex:', index)\n",
    "                    value_attr = df[col][index]  ####\n",
    "                    # if value_attr == ' ':\n",
    "                    # print(f'{device}:{proto}:{col} --> {value_attr}')\n",
    "                    # making a flow signature\n",
    "                    value_flow = df[' srcIp'][index] + '-' + df[' dstIp'][index] + '-' + str(df[' ipProto'][index]) + '-' + str(df[' srcPort'][index]) + '-' + str(df[' dstPort'][index])\n",
    "                    \n",
    "                    if df[' ipProto'][index] == 6 and (df[' srcPort'][index]==443 or df[' dstPort'][index]==443):\n",
    "                        if value_attr not in attr_name_dict_standardPort:\n",
    "                            attr_name_dict_standardPort[value_attr] = 0\n",
    "                        attr_name_dict_standardPort[value_attr] += 1\n",
    "                    else:  # non-standard port\n",
    "                        if value_attr not in attr_name_dict_NONstandardPort:\n",
    "                            attr_name_dict_NONstandardPort[value_attr] = 0\n",
    "                        attr_name_dict_NONstandardPort[value_attr] += 1\n",
    "\n",
    "                        # recording the non-standard flow used\n",
    "                        flowSig = str(df[' ipProto'][index]) + '-' + str(df[' srcPort'][index]) + '-' + str(df[' dstPort'][index])\n",
    "                        if flowSig not in non_standard_MUDFlows:\n",
    "                            non_standard_MUDFlows[flowSig] = 0\n",
    "                        non_standard_MUDFlows[flowSig] += 1                \n",
    "\n",
    "                    if value_flow not in unique_flows_using_attribute:  # adding unique flow with a violation\n",
    "                        unique_flows_using_attribute.append(value_flow)  \n",
    "                        # num_violated_flows += 1\n",
    "                # attr_name_dict['unique_flows_using_attribute'] = []  # unique_flows_using_attribute  # commented out because not needed at this point, can uncomment to be used later\n",
    "                # attr_name_dict['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "                attr[col] = {'standard': attr_name_dict_standardPort, 'nonstandard': attr_name_dict_NONstandardPort}\n",
    "\n",
    "            attr['number_of_unique_flows'] = len(unique_flows_using_attribute)\n",
    "            attr['nonstandard_flows'] = non_standard_MUDFlows\n",
    "            unique_attr_proto[proto] = attr\n",
    "            print(f'\\t\\t\\tnumber of unique flows: ', len(unique_flows_using_attribute))\n",
    "\n",
    "    # #####################################################################\n",
    "    # df_to_save_temp = pd.DataFrame(unique_attr_proto)\n",
    "    # # Specify the output CSV file path\n",
    "    # output_file = '../../results/attributes/delete/'+device+'.csv'\n",
    "    # # if os.path.exists(output_dir):\n",
    "    # #     shutil.rmtree(output_dir)\n",
    "    # # os.mkdir(output_dir)\n",
    "    # # Write the DataFrame to the CSV file\n",
    "    # df_to_save_temp.to_csv(df_to_save_temp, index=True, sep='|')\n",
    "    # #####################################################################\n",
    "\n",
    "    unique_attr_device[device] = unique_attr_proto\n",
    "\n",
    "# with open('output2.json', 'w') as json_file:\n",
    "#     json.dump(unique_viol_device, json_file)\n",
    "# print(unique_attr_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_save = pd.DataFrame(unique_attr_device)\n",
    "# df_to_save['TPLinkCamera']['classic-stun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwairAirQuality</th>\n",
       "      <th>LiFXBulb</th>\n",
       "      <th>TPLinkCamera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tls</th>\n",
       "      <td>{'client-hello-cipher-suites': {'standard': {'...</td>\n",
       "      <td>{'client-hello-cipher-suites': {'standard': {}...</td>\n",
       "      <td>{'client-hello-extensions': {'standard': {}, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       AwairAirQuality  \\\n",
       "tls  {'client-hello-cipher-suites': {'standard': {'...   \n",
       "\n",
       "                                              LiFXBulb  \\\n",
       "tls  {'client-hello-cipher-suites': {'standard': {}...   \n",
       "\n",
       "                                          TPLinkCamera  \n",
       "tls  {'client-hello-extensions': {'standard': {}, '...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_save = pd.DataFrame(unique_attr_device)\n",
    "\n",
    "# Specify the output CSV file path\n",
    "# final_output_file = '../../results/attributes/v1_request_attributes.csv'  # define in the beginning\n",
    "\n",
    "# Write the DataFrame to the CSV file\n",
    "df_to_save.to_csv(final_output_file, index=True, sep='|')\n",
    "\n",
    "df_to_save.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
